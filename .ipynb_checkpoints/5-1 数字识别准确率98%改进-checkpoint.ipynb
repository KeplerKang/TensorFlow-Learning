{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy 0.9361,Learning Rate0.001\n",
      "Iter1,Testing Accuracy 0.9526,Learning Rate0.00095\n",
      "Iter2,Testing Accuracy 0.9588,Learning Rate0.0009025\n",
      "Iter3,Testing Accuracy 0.9619,Learning Rate0.000857375\n",
      "Iter4,Testing Accuracy 0.9643,Learning Rate0.00081450626\n",
      "Iter5,Testing Accuracy 0.9677,Learning Rate0.0007737809\n",
      "Iter6,Testing Accuracy 0.9685,Learning Rate0.0007350919\n",
      "Iter7,Testing Accuracy 0.9691,Learning Rate0.0006983373\n",
      "Iter8,Testing Accuracy 0.97,Learning Rate0.0006634204\n",
      "Iter9,Testing Accuracy 0.9728,Learning Rate0.0006302494\n",
      "Iter10,Testing Accuracy 0.9733,Learning Rate0.0005987369\n",
      "Iter11,Testing Accuracy 0.9747,Learning Rate0.0005688001\n",
      "Iter12,Testing Accuracy 0.9744,Learning Rate0.0005403601\n",
      "Iter13,Testing Accuracy 0.9743,Learning Rate0.0005133421\n",
      "Iter14,Testing Accuracy 0.9756,Learning Rate0.000487675\n",
      "Iter15,Testing Accuracy 0.9761,Learning Rate0.00046329122\n",
      "Iter16,Testing Accuracy 0.9758,Learning Rate0.00044012666\n",
      "Iter17,Testing Accuracy 0.9771,Learning Rate0.00041812033\n",
      "Iter18,Testing Accuracy 0.9758,Learning Rate0.00039721432\n",
      "Iter19,Testing Accuracy 0.9771,Learning Rate0.0003773536\n",
      "Iter20,Testing Accuracy 0.9767,Learning Rate0.00035848594\n",
      "Iter21,Testing Accuracy 0.9772,Learning Rate0.00034056162\n",
      "Iter22,Testing Accuracy 0.9777,Learning Rate0.00032353355\n",
      "Iter23,Testing Accuracy 0.9775,Learning Rate0.00030735688\n",
      "Iter24,Testing Accuracy 0.9781,Learning Rate0.000291989\n",
      "Iter25,Testing Accuracy 0.9771,Learning Rate0.00027738957\n",
      "Iter26,Testing Accuracy 0.9786,Learning Rate0.0002635201\n",
      "Iter27,Testing Accuracy 0.9782,Learning Rate0.00025034408\n",
      "Iter28,Testing Accuracy 0.9794,Learning Rate0.00023782688\n",
      "Iter29,Testing Accuracy 0.9791,Learning Rate0.00022593554\n",
      "Iter30,Testing Accuracy 0.9794,Learning Rate0.00021463877\n",
      "Iter31,Testing Accuracy 0.9802,Learning Rate0.00020390682\n",
      "Iter32,Testing Accuracy 0.9797,Learning Rate0.00019371149\n",
      "Iter33,Testing Accuracy 0.9802,Learning Rate0.0001840259\n",
      "Iter34,Testing Accuracy 0.98,Learning Rate0.00017482461\n",
      "Iter35,Testing Accuracy 0.9801,Learning Rate0.00016608338\n",
      "Iter36,Testing Accuracy 0.9802,Learning Rate0.00015777921\n",
      "Iter37,Testing Accuracy 0.9806,Learning Rate0.00014989026\n",
      "Iter38,Testing Accuracy 0.981,Learning Rate0.00014239574\n",
      "Iter39,Testing Accuracy 0.9807,Learning Rate0.00013527596\n",
      "Iter40,Testing Accuracy 0.9812,Learning Rate0.00012851215\n",
      "Iter41,Testing Accuracy 0.9817,Learning Rate0.00012208655\n",
      "Iter42,Testing Accuracy 0.9811,Learning Rate0.00011598222\n",
      "Iter43,Testing Accuracy 0.9797,Learning Rate0.00011018311\n",
      "Iter44,Testing Accuracy 0.9812,Learning Rate0.000104673956\n",
      "Iter45,Testing Accuracy 0.9816,Learning Rate9.944026e-05\n",
      "Iter46,Testing Accuracy 0.9809,Learning Rate9.446825e-05\n",
      "Iter47,Testing Accuracy 0.9809,Learning Rate8.974483e-05\n",
      "Iter48,Testing Accuracy 0.9811,Learning Rate8.525759e-05\n",
      "Iter49,Testing Accuracy 0.9814,Learning Rate8.099471e-05\n",
      "Iter50,Testing Accuracy 0.9804,Learning Rate7.6944976e-05\n"
     ]
    }
   ],
   "source": [
    "#改进\n",
    "#增加了lr变量，使学习率在动态的变小，进而使算法优化\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#定义每个批次的大小\n",
    "batch_size = 100 #即每次直接放入100张图片进入神经网络训练           \n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784]) #28*28 = 784 将图片展开成为一维\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.01,dtype=tf.float32)\n",
    "#改进#增加一个placeholder用于dropout改进\n",
    "\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "#改进#初始化参数的时候加上一个初始值\n",
    "W1 = tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "#正态分布式初始化\n",
    "b1 = tf.Variable(tf.zeros([500])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)#dropout函数，L代表某一层的输出，keep_prob代表多少比例的神经元工作\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([500,300],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([300])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([300,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L2_drop,W3) + b3)\n",
    "#softmax激活函数：使用e的n次方除以e的n次方总和，扩大概率之间的差异，选取最大概率的数值\n",
    "\n",
    "#最大似然代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "\n",
    "#使用梯度下降法\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#改进#更好的优化器\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)#1e-2指十的-2次方即0.01的学习率\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个bool型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#argmax(a,b)函数的含义：求矩阵a按照b方式（0是按列取，1是按行取）的最大值的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "#tf.cast是强制转换类型函数，将bool转换为float\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(51):\n",
    "        sess.run(tf.assign(lr,0.001 * (0.95 ** epoch)))\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #将图片的数据以及标签读入程序\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        learning_rate = sess.run(lr)\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuracy \" + str(acc) + \",Learning Rate\" + str(learning_rate))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
