{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy 0.9322,Training Accuracy0.9332909\n",
      "Iter1,Testing Accuracy 0.9471,Training Accuracy0.9533091\n",
      "Iter2,Testing Accuracy 0.9573,Training Accuracy0.9653636\n",
      "Iter3,Testing Accuracy 0.9625,Training Accuracy0.97367275\n",
      "Iter4,Testing Accuracy 0.9653,Training Accuracy0.9779091\n",
      "Iter5,Testing Accuracy 0.9705,Training Accuracy0.98210907\n",
      "Iter6,Testing Accuracy 0.9718,Training Accuracy0.98536366\n",
      "Iter7,Testing Accuracy 0.973,Training Accuracy0.9877091\n",
      "Iter8,Testing Accuracy 0.9746,Training Accuracy0.9894\n",
      "Iter9,Testing Accuracy 0.9751,Training Accuracy0.9906909\n",
      "Iter10,Testing Accuracy 0.9747,Training Accuracy0.9917273\n",
      "Iter11,Testing Accuracy 0.9772,Training Accuracy0.99256366\n",
      "Iter12,Testing Accuracy 0.9766,Training Accuracy0.9935273\n",
      "Iter13,Testing Accuracy 0.9768,Training Accuracy0.99398184\n",
      "Iter14,Testing Accuracy 0.977,Training Accuracy0.9942182\n",
      "Iter15,Testing Accuracy 0.9768,Training Accuracy0.9949091\n",
      "Iter16,Testing Accuracy 0.9781,Training Accuracy0.9953273\n",
      "Iter17,Testing Accuracy 0.9791,Training Accuracy0.9956727\n",
      "Iter18,Testing Accuracy 0.9793,Training Accuracy0.99594545\n",
      "Iter19,Testing Accuracy 0.98,Training Accuracy0.9963091\n",
      "Iter20,Testing Accuracy 0.9798,Training Accuracy0.9966\n",
      "Iter21,Testing Accuracy 0.98,Training Accuracy0.9966909\n",
      "Iter22,Testing Accuracy 0.9767,Training Accuracy0.99625456\n",
      "Iter23,Testing Accuracy 0.9787,Training Accuracy0.9965091\n",
      "Iter24,Testing Accuracy 0.9794,Training Accuracy0.99692726\n",
      "Iter25,Testing Accuracy 0.9796,Training Accuracy0.9970545\n",
      "Iter26,Testing Accuracy 0.9782,Training Accuracy0.99703634\n",
      "Iter27,Testing Accuracy 0.9806,Training Accuracy0.99725455\n",
      "Iter28,Testing Accuracy 0.9784,Training Accuracy0.9970545\n",
      "Iter29,Testing Accuracy 0.9779,Training Accuracy0.9969818\n",
      "Iter30,Testing Accuracy 0.9793,Training Accuracy0.99743634\n",
      "Iter31,Testing Accuracy 0.9808,Training Accuracy0.99758184\n",
      "Iter32,Testing Accuracy 0.9806,Training Accuracy0.9976182\n",
      "Iter33,Testing Accuracy 0.9806,Training Accuracy0.99765456\n",
      "Iter34,Testing Accuracy 0.9806,Training Accuracy0.99774545\n",
      "Iter35,Testing Accuracy 0.9791,Training Accuracy0.9977273\n",
      "Iter36,Testing Accuracy 0.9799,Training Accuracy0.9978\n",
      "Iter37,Testing Accuracy 0.9808,Training Accuracy0.99785453\n",
      "Iter38,Testing Accuracy 0.978,Training Accuracy0.9975273\n",
      "Iter39,Testing Accuracy 0.9809,Training Accuracy0.99790907\n",
      "Iter40,Testing Accuracy 0.9801,Training Accuracy0.9979454\n",
      "Iter41,Testing Accuracy 0.9799,Training Accuracy0.9979636\n",
      "Iter42,Testing Accuracy 0.981,Training Accuracy0.99798185\n",
      "Iter43,Testing Accuracy 0.9809,Training Accuracy0.9980182\n",
      "Iter44,Testing Accuracy 0.9812,Training Accuracy0.99805456\n",
      "Iter45,Testing Accuracy 0.9786,Training Accuracy0.99798185\n",
      "Iter46,Testing Accuracy 0.9811,Training Accuracy0.99807274\n",
      "Iter47,Testing Accuracy 0.9811,Training Accuracy0.99807274\n",
      "Iter48,Testing Accuracy 0.9813,Training Accuracy0.9980909\n",
      "Iter49,Testing Accuracy 0.9812,Training Accuracy0.9981091\n",
      "Iter50,Testing Accuracy 0.9802,Training Accuracy0.99814546\n"
     ]
    }
   ],
   "source": [
    "#改进\n",
    "#添加三层隐藏层，增加网络训练，使用dropout解决过拟合问题，使用更好的优化器\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#定义每个批次的大小\n",
    "batch_size = 100 #即每次直接放入100张图片进入神经网络训练           \n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784]) #28*28 = 784 将图片展开成为一维\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "#改进#增加一个placeholder用于dropout改进\n",
    "\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "#改进#初始化参数的时候加上一个初始值\n",
    "W1 = tf.Variable(tf.truncated_normal([784,1000],stddev=0.1))\n",
    "#正态分布式初始化\n",
    "b1 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)#dropout函数，L代表某一层的输出，keep_prob代表多少比例的神经元工作\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([1000,500],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([500])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([500,100],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([100,10],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4) + b4)\n",
    "#softmax激活函数：使用e的n次方除以e的n次方总和，扩大概率之间的差异，选取最大概率的数值\n",
    "\n",
    "#最大似然代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "\n",
    "#使用梯度下降法\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#改进#更好的优化器\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)#1e-2指十的-2次方即0.01的学习率\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个bool型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#argmax(a,b)函数的含义：求矩阵a按照b方式（0是按列取，1是按行取）的最大值的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "#tf.cast是强制转换类型函数，将bool转换为float\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(51):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #将图片的数据以及标签读入程序\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "            \n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuracy \" + str(test_acc) + \",Training Accuracy\" + str(train_acc))\n",
    "        \n",
    "#dropout神经元使用比例设置之后，消除了过拟合现象，使训练数据与测试数据的准确率接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#运行结果\n",
    "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
    "Iter0,Testing Accuracy 0.9466,Training Accuracy0.9584727\n",
    "Iter1,Testing Accuracy 0.9543,Training Accuracy0.9721636\n",
    "Iter2,Testing Accuracy 0.9593,Training Accuracy0.98176366\n",
    "Iter3,Testing Accuracy 0.9643,Training Accuracy0.9860727\n",
    "Iter4,Testing Accuracy 0.9666,Training Accuracy0.9883818\n",
    "Iter5,Testing Accuracy 0.966,Training Accuracy0.9899273\n",
    "Iter6,Testing Accuracy 0.9673,Training Accuracy0.9908909\n",
    "Iter7,Testing Accuracy 0.9681,Training Accuracy0.9918\n",
    "Iter8,Testing Accuracy 0.9684,Training Accuracy0.9922364\n",
    "Iter9,Testing Accuracy 0.9697,Training Accuracy0.9928\n",
    "Iter10,Testing Accuracy 0.9701,Training Accuracy0.99325454\n",
    "Iter11,Testing Accuracy 0.9708,Training Accuracy0.99349093\n",
    "Iter12,Testing Accuracy 0.9707,Training Accuracy0.99365455\n",
    "Iter13,Testing Accuracy 0.971,Training Accuracy0.9938545\n",
    "Iter14,Testing Accuracy 0.9711,Training Accuracy0.9941273\n",
    "Iter15,Testing Accuracy 0.9708,Training Accuracy0.9942727\n",
    "Iter16,Testing Accuracy 0.9704,Training Accuracy0.9944182\n",
    "Iter17,Testing Accuracy 0.9716,Training Accuracy0.9945091\n",
    "Iter18,Testing Accuracy 0.9722,Training Accuracy0.9945818\n",
    "Iter19,Testing Accuracy 0.9715,Training Accuracy0.99465454\n",
    "Iter20,Testing Accuracy 0.9719,Training Accuracy0.9947636\n",
    "Iter21,Testing Accuracy 0.9714,Training Accuracy0.99485457\n",
    "Iter22,Testing Accuracy 0.9717,Training Accuracy0.99494547\n",
    "Iter23,Testing Accuracy 0.9714,Training Accuracy0.99505454\n",
    "Iter24,Testing Accuracy 0.9716,Training Accuracy0.9951636\n",
    "Iter25,Testing Accuracy 0.9715,Training Accuracy0.9952\n",
    "Iter26,Testing Accuracy 0.9721,Training Accuracy0.99527276\n",
    "Iter27,Testing Accuracy 0.9716,Training Accuracy0.99529094\n",
    "Iter28,Testing Accuracy 0.972,Training Accuracy0.99529094\n",
    "Iter29,Testing Accuracy 0.9724,Training Accuracy0.99536365\n",
    "Iter30,Testing Accuracy 0.9724,Training Accuracy0.9954727"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
