{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Iter0,Testing Accuracy 0.8647\n",
      "Iter1,Testing Accuracy 0.9694\n",
      "Iter2,Testing Accuracy 0.9756\n",
      "Iter3,Testing Accuracy 0.9796\n",
      "Iter4,Testing Accuracy 0.9817\n",
      "Iter5,Testing Accuracy 0.9853\n",
      "Iter6,Testing Accuracy 0.9857\n",
      "Iter7,Testing Accuracy 0.9886\n",
      "Iter8,Testing Accuracy 0.9884\n",
      "Iter9,Testing Accuracy 0.9881\n",
      "Iter10,Testing Accuracy 0.9904\n",
      "Iter11,Testing Accuracy 0.9882\n",
      "Iter12,Testing Accuracy 0.9905\n",
      "Iter13,Testing Accuracy 0.9909\n",
      "Iter14,Testing Accuracy 0.991\n",
      "Iter15,Testing Accuracy 0.9903\n",
      "Iter16,Testing Accuracy 0.9913\n",
      "Iter17,Testing Accuracy 0.9909\n",
      "Iter18,Testing Accuracy 0.9921\n",
      "Iter19,Testing Accuracy 0.9915\n",
      "Iter20,Testing Accuracy 0.9917\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#定义每个批次的大小\n",
    "batch_size = 100 #即每次直接放入100张图片进入神经网络训练           \n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#初始化权值\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)#生成一个截断的正态分布\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#初始化偏置\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#卷积层\n",
    "def conv2d(x,W):\n",
    "    # x input tensor of shape [batch,in_height,in_width,in_channels]\n",
    "    # W filter / kernel tensor of shape [filter_height,filter_width,in_channels,out_channels]\n",
    "    # strides[0] = strides[3] = 1 (恒为1）. strides[1]代表x方向的步长，strides[2]代表y方向的步长\n",
    "    #前后都是1是因为，第一个x维度是块，也是第几张图片，对每个图片进行操作肯定是一步一步的移动，\n",
    "    #第四个维度也是1是因为对每个通道也是要操作，也要一步一步的移动。所以前后都是1，表示一步\n",
    "    # padding: A string from :'SAME' , 'VALID'（same会补0，使前后大小一致，valid则不补0）\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "#池化层\n",
    "def max_pool_2x2(x):\n",
    "    #ksize [1,x,y,1] 窗口的大小 \n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "\n",
    "#定义placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#改变x的格式转为4D的向量[batch,in_height,in_width,in_channels]\n",
    "#-1表示任意，由程序其它部分给出，in_channels指通道数，取决于图片的维度\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "#初始化第一个卷积层的权值和偏置\n",
    "W_conv1 = weight_variable([5,5,1,32])#5*5的采样窗口，32个卷积核从1平面抽取特征\n",
    "b_conv1 = bias_variable([32])#每一个卷积核一个偏置值\n",
    "\n",
    "#把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)#进行max-poolong\n",
    "\n",
    "#初始化第二个卷积层的权值和偏置\n",
    "W_conv2 = weight_variable([5,5,32,64])#5*5的采样窗口，32个卷积核从1平面抽取特征\n",
    "b_conv2 = bias_variable([64])#每一个卷积核一个偏置值\n",
    "\n",
    "#把h_pool1和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)#进行max-poolong\n",
    "\n",
    "# 28*28的图片第一次卷积后还是28*28，第一次池化后变为14*14\n",
    "# 第二次卷积后为14*14，第二次池化后变为7*7\n",
    "# 经过上面操作后得到64张7*7的平面\n",
    "\n",
    "#初始化第一个全连接层的权值\n",
    "W_fc1 = weight_variable([7*7*64,1024])#上一场有7*7*64个神经元，全连接层有1024个神经元\n",
    "b_fc1 = bias_variable([1024])#1024个节点\n",
    "\n",
    "#把池化层2的输出扁平化为1维\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "#求第一个全连接层的输出\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "\n",
    "#keep_prob用来表示神经元的输出概率\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "#初始化第二个全连接层\n",
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "#计算输出\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)\n",
    "\n",
    "#交叉熵代价函数\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用AdamOptimizer进行优化\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "#初始化变量\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "#结果存放在一个bool型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "#argmax(a,b)函数的含义：求矩阵a按照b方式（0是按列取，1是按行取）的最大值的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "#tf.cast是强制转换类型函数，将bool转换为float\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #将图片的数据以及标签读入程序\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuracy \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iter0,Testing Accuracy 0.8647\n",
    "Iter1,Testing Accuracy 0.9694\n",
    "Iter2,Testing Accuracy 0.9756\n",
    "Iter3,Testing Accuracy 0.9796\n",
    "Iter4,Testing Accuracy 0.9817\n",
    "Iter5,Testing Accuracy 0.9853\n",
    "Iter6,Testing Accuracy 0.9857\n",
    "Iter7,Testing Accuracy 0.9886\n",
    "Iter8,Testing Accuracy 0.9884\n",
    "Iter9,Testing Accuracy 0.9881\n",
    "Iter10,Testing Accuracy 0.9904\n",
    "Iter11,Testing Accuracy 0.9882\n",
    "Iter12,Testing Accuracy 0.9905\n",
    "Iter13,Testing Accuracy 0.9909\n",
    "Iter14,Testing Accuracy 0.991\n",
    "Iter15,Testing Accuracy 0.9903\n",
    "Iter16,Testing Accuracy 0.9913\n",
    "Iter17,Testing Accuracy 0.9909\n",
    "Iter18,Testing Accuracy 0.9921\n",
    "Iter19,Testing Accuracy 0.9915\n",
    "Iter20,Testing Accuracy 0.9917"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
